from stable_baselines3 import PPO
from stable_baselines3.common.env_util import make_vec_env
import joblib
from Scripts.Data_Fetchers.trading_functions import TradingEnv
import pandas as pd

def train_drl_model(data_file_path, total_timesteps=10000, transaction_cost=0.001):
    # Load and preprocess data
    data = pd.read_csv(data_file_path)
    env = make_vec_env(lambda: TradingEnv(data, transaction_cost), n_envs=1)
    model = PPO('MlpPolicy', env, verbose=1)
    model.learn(total_timesteps=total_timesteps)
    model.save("ppo_trading_model")
    
    scaler_path = "scaler.pkl"
    joblib.dump(env, scaler_path)  # Save the scaler used for preprocessing the data
    return model, scaler_path
